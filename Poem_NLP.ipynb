{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7ecb6da-73ec-44ed-a2d2-9641da8983fe",
   "metadata": {},
   "source": [
    "# Poem Classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8977ba5a-3473-45c0-ae1d-552b10945ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07ac6bd7-f964-4b72-9e47-7eabedffc0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Poem_classification - train_data.csv')\n",
    "test = pd.read_csv('Poem_classification - test_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb74c36-e02f-4806-ac43-97b38cba8aef",
   "metadata": {},
   "source": [
    "# Check the duplicates and null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1afc0256-1074-4e78-878e-4cdaecf24874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train duplicates: 4\n",
      "Test duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train duplicates: {train.duplicated().sum()}\")\n",
    "print(f\"Test duplicates: {test.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf3486f2-c471-4f58-a881-95017f21195e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train nulls:\n",
      " Genre    0\n",
      "Poem     4\n",
      "dtype: int64\n",
      "Test nulls:\n",
      " Genre    0\n",
      "Poem     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train nulls:\\n {train.isnull().sum()}\")\n",
    "print(f\"Test nulls:\\n {test.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f1af17a-c21c-4880-8322-ec48be11cb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the duplicates and null values\n",
    "train.drop_duplicates(inplace=True)\n",
    "train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba30872c-3b47-4b7b-957b-8cfcd4f129f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27c893a3-1320-47d0-a4b5-2b3d8de3aa90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Poem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Music</td>\n",
       "      <td>In the thick brushthey spend the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Music</td>\n",
       "      <td>Storms are generous.                       ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Genre                                               Poem\n",
       "1  Music                In the thick brushthey spend the...\n",
       "2  Music     Storms are generous.                       ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ea46f9-a739-460c-97b6-f81daec368bd",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c19f19a6-b959-4aeb-92f0-6e8b9944ef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da670537-ae87-4cf9-a59a-1765f8433866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower the text\n",
    "train['Poem'] = train['Poem'].apply(lambda x: x.lower())\n",
    "test['Poem'] = test['Poem'].apply(lambda x: x.lower())\n",
    "\n",
    "# Remove special characters\n",
    "train['Poem'] = train['Poem'].apply(lambda x: re.sub(r'[^a-z A-z 0-9]+', '', x))\n",
    "test['Poem'] = test['Poem'].apply(lambda x: re.sub(r'[^a-z A-z 0-9]+', '', x))\n",
    "\n",
    "# Remove stopwords \n",
    "train['Poem'] = train['Poem'].apply(lambda x: \" \".join([i for i in x.split() if i not in stopwords.words('english')]))\n",
    "test['Poem'] = test['Poem'].apply(lambda x: \" \".join([i for i in x.split() if i not in stopwords.words('english')]))\n",
    "\n",
    "# Remove URLs \n",
    "train['Poem'] = train['Poem'].apply(lambda x: re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '', x))\n",
    "test['Poem'] = test['Poem'].apply(lambda x: re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '', x))\n",
    "\n",
    "# Remove HTML\n",
    "train['Poem'] = train['Poem'].apply(lambda x: BeautifulSoup(x, 'lxml').get_text())\n",
    "test['Poem'] = test['Poem'].apply(lambda x: BeautifulSoup(x, 'lxml').get_text())\n",
    "\n",
    "# Remove Extra spaces\n",
    "train['Poem'] = train['Poem'].apply(lambda x: \" \".join(x.split()))\n",
    "test['Poem'] = test['Poem'].apply(lambda x: \" \".join(x.split()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e4b0f5-9a80-40a6-aa71-a17efe1642f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4492680b-a68f-409a-ba3b-888ad78f5346",
   "metadata": {},
   "source": [
    "# Lemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04d29a0f-56b1-4b49-8523-25961923c21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def text_lemma(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(i) for i in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43782b89-c133-4e2f-99e7-27629d0fe56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Poem'] = train['Poem'].apply(lambda x: text_lemma(x))\n",
    "test['Poem'] = test['Poem'].apply(lambda x: text_lemma(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f65702-1ba7-48c4-b0ae-fa4fd534a725",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "207b48d8-af7b-4b8f-a29e-7a8fb5d7f1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Music', 'Death', 'Affection', 'Environment'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Genre'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70ce26d8-e018-4818-9ed4-e685d319bf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "oe = OrdinalEncoder(categories=[['Music', 'Death', 'Affection', 'Environment']])\n",
    "train['Genre'] = oe.fit_transform(train[['Genre']])\n",
    "test['Genre'] = oe.transform(test[['Genre']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "156afe05-d2c7-4dbb-954e-d3bc9bca76cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Genre'] = train['Genre'].astype(int)\n",
    "test['Genre'] = test['Genre'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59584fe-4914-4831-8831-0e174296e605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ebd40d-3b4c-4591-a810-67f120b8c8e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3554eb7d-947d-423f-aa10-269c8c172fb7",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1bbd6a5-ec48-4eb4-9cb9-36d9a976c199",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns='Genre')\n",
    "y_train = train['Genre']\n",
    "X_test = test.drop(columns='Genre')\n",
    "y_test = test['Genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74ba854c-17be-4c70-ab77-03eeb5549265",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train['Poem'].to_list()\n",
    "X_test = X_test['Poem'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dc6a16-3341-4718-8c29-18af38c7323c",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72892f9a-53ad-4486-9d58-d3cf1ea95609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c58ec31-b3f8-4108-91a6-c7c117c702be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83855749-1396-46d7-8ffe-bea0f8a09fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('word2vec.model', 'rb') as f:\n",
    "    wv2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e6046b-4854-4885-80e2-134e134179d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34cb6e10-fa66-41a8-b400-258fa9be8b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def avg_w2v(sent, model):\n",
    "    vectors = [model.wv[word] for word in sent if word in model.wv.index_to_key]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "475af7fc-6406-4365-a3b3-1d82564ac30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 835/835 [00:00<00:00, 8481.53it/s]\n",
      "100%|██████████████████████████████████████| 150/150 [00:00<00:00, 10012.02it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_vec = np.array([avg_w2v(sent, model) for sent in tqdm(X_train)])\n",
    "X_test_vec = np.array([avg_w2v(sent, model) for sent in tqdm(X_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeabe1b-8319-439b-8f99-5d18b1eda585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41003472-c905-4049-b5c3-fcf655f23692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47471351-a0b6-4eb3-bba0-e3889bff0bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "071f63f9-d91c-4e06-b891-399e0370949c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44666666666666666"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GaussianNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_vec, y_train)\n",
    "y_pred = gnb.predict(X_test_vec)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f8f322-97d6-431f-bf58-acfe8d438ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
